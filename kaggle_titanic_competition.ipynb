{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Titanic Survival Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the dataset\n",
    "\n",
    "First an foremost I want to understand what the dataset that I am working with looks like. A few general questions that I want to answer are:\n",
    "\n",
    "- What are the different columns? How many are there?\n",
    "- What does the data look like?\n",
    "- What data types are in the dataset?\n",
    "- How many entries are there in the dataset? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "titanic_df = pd.read_csv('./data/train.csv')\n",
    "\n",
    "print(titanic_df.columns)\n",
    "print(len(titanic_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass                     Name   Sex   Age  SibSp  \\\n",
      "0            1         0       3  Braund, Mr. Owen Harris  male  22.0      1   \n",
      "\n",
      "   Parch     Ticket  Fare Cabin Embarked  \n",
      "0      0  A/5 21171  7.25   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "print(titanic_df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(titanic_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 891\n"
     ]
    }
   ],
   "source": [
    "num_entries = titanic_df.shape[0]\n",
    "print(\"Number of entries:\", num_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "In the cleaning process I am doing some data checking and manipulation tasks that will hopefully improve the usability and quality of precitions in the later steps. \n",
    "\n",
    "These include:\n",
    "- Possibly dropping unnecessary columns\n",
    "- Handling missing values by either removing the entries, or adding data\n",
    "- Type checking & possibly converting them to more suitable types\n",
    "- Removing duplicate data\n",
    "- Possibly adapting granularity of the data (either making it less or more granular)\n",
    "- Finding outliers and handling them appropriately\n",
    "- Possibly adding new features with feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First I create a deep copy to guarantee that the original dataframe stays as it is\n",
    "t_df = titanic_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping/ removing the PassengerID column\n",
    "\n",
    "As each row already has an ID, the PassengerID column is redundant and can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df = t_df.drop('PassengerId', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing values\n",
    "\n",
    "One way of dealing with missing values would be to infer the data from similar entries, rather than removing the entry altogether. For example, suppose we have a passenger with a missing value for cabin:\n",
    "\n",
    "- We could try to find out if they are married to another passenger by checking the name.\n",
    "- We could check if the class gives us a rough estimate of where the cabin would be.\n",
    "- We could check the price to infer what type of cabin it might be and where it would be located.\n",
    "\n",
    "Whilst this may sound sensible, it is by no means a hard and fast rule and could therefore make the model perform worse. It is therefore a good idea to split the datasets into two versions: one where all the entries with missing values are removed, and one where the missing values are inferred from other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived       bool\n",
      "Pclass         int8\n",
      "Name         object\n",
      "Sex          object\n",
      "Age         float64\n",
      "SibSp         int64\n",
      "Parch          int8\n",
      "Ticket       object\n",
      "Fare        float64\n",
      "Cabin        object\n",
      "Embarked     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "t_df['Pclass'] = t_df['Pclass'].astype('int8')\n",
    "#Â t_df['Age'] = t_df['Age'].astype('int8')\n",
    "t_df['Parch'] = t_df['Parch'].astype('int8')\n",
    "t_df['Survived'] = t_df['Survived'].astype('bool')\n",
    "print(t_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for duplicates\n",
    "\n",
    "First we sort the data, then we check for duplicates. It is important to sort the data first, since the duplicated() method only compare each row to the previous row. So if there are rows between duplicates, the duplicated() method will not catch these.\n",
    "\n",
    "For the sorting values I chose the 'Ticket' and 'Cabin' features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "t_df_sorted = t_df.sort_values(by=['Ticket', 'Cabin'])\n",
    "\n",
    "duplicates = t_df_sorted.duplicated()\n",
    "number_duplicate = duplicates.sum()\n",
    "print(\"Number of duplicates:\",number_duplicate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the questions to be answered\n",
    "\n",
    "The overall question is: What are the main factors that contributed to the survival rate of a passenger on the Titanic?\n",
    "\n",
    "### Defining the assumptions to test\n",
    "\n",
    "To build a successful model that attempts to predict survivability, it is first necessary to find related features. To find possible features that affect survivability, I first define some assumptions that I want to test:\n",
    "\n",
    "- Age has an effect on survivability (due to the fitness of the individual)\n",
    "- The cabin has an effect on survivability (due to proximity to exits, etc.)\n",
    "- Class has an effect on survivability (due to the fact that higher class passengers had priority on emergency ships)\n",
    "- Tickets and cabins are a proxy for class and therefore affect survivability (they reflect the class of passenger).\n",
    "\n",
    "Please note that these assumptions are completely made up and based on intuition. They are just there to give me something to work with and investigate. Even if there is a relationship between survivability and the feature, this does not necessarily mean that there is a correlation or proof of my initial assumption."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
